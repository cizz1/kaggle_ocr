{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport os\nfrom PIL import Image\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import VisionEncoderDecoderModel, ViTFeatureExtractor, AutoTokenizer, Trainer, TrainingArguments","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv(\"/kaggle/input/ai-of-god-3/train.csv\")\ntest_df = pd.read_csv(\"/kaggle/input/ai-of-god-3/test.csv\"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CustomDataset(Dataset):\n    def __init__(self, dataframe, base_dir, feature_extractor, tokenizer=None, is_test=False):\n        self.df = dataframe\n        self.base_dir = base_dir\n        self.feature_extractor = feature_extractor\n        self.tokenizer = tokenizer\n        self.is_test = is_test\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        if self.is_test:\n            page, line = row['unique Id'].split('_')[1:3]\n            image_path = os.path.join(self.base_dir, f\"Page_{page}\", f\"L_{line}.png\")\n        else:\n            image_path = os.path.join(self.base_dir, f\"{row['unique Id']}.png\")\n\n        if not os.path.exists(image_path):\n            print(f\"Warning: Image {image_path} not found.\")\n            return None\n\n        image = Image.open(image_path).convert(\"RGB\")\n        inputs = self.feature_extractor(images=image, return_tensors=\"pt\")\n\n        if self.tokenizer is not None and not self.is_test:\n            inputs['labels'] = self.tokenizer(row['transcription'], padding=\"max_length\", truncation=True, return_tensors=\"pt\").input_ids\n\n        return {key: val.squeeze() for key, val in inputs.items()}","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_name = \"nlpconnect/vit-gpt2-image-captioning\"\nmodel = VisionEncoderDecoderModel.from_pretrained(model_name)\nfeature_extractor = ViTFeatureExtractor.from_pretrained(model_name)\ntokenizer = AutoTokenizer.from_pretrained(model_name)\n\n# Create dataset instances\ntrain_dataset = CustomDataset(train_df, \"/kaggle/input/ai-of-god-3/train_images\", feature_extractor, tokenizer)\ntest_dataset = CustomDataset(test_df, \"/kaggle/input/ai-of-god-3/test_images\", feature_extractor, is_test=True)\n\n# Create DataLoaders\ntrain_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=8)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for param in model.parameters():\n    param.requires_grad = False\n\n# Unfreeze the final layers\nfor param in model.decoder.transformer.h[-1].parameters():\n    param.requires_grad = True\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir=\"./results\",\n    evaluation_strategy=\"epoch\",\n    per_device_train_batch_size=4,\n    per_device_eval_batch_size=4,\n    num_train_epochs=3,\n    save_strategy=\"epoch\",\n    logging_dir='./logs',\n)\n\n# Training loop\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=test_dataset\n)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.train()","metadata":{},"execution_count":null,"outputs":[]}]}